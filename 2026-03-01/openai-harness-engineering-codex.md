# OpenAI 内部实验：100 万行代码，0 行手写 — Codex Agent-First 工程实践全解析

> **TL;DR**: OpenAI 团队用 5 个月时间做了一个极端实验 — **一个真实产品的所有代码 100% 由 Codex 生成，人类一行代码都没写**。最终产出**百万行代码、1500+ PR**，每个工程师日均 3.5 个 PR。核心教训：**给 Agent 一张地图，不是千页手册。纪律体现在脚手架而非代码本身。** "无聊"的技术栈反而最适合 Agent。

---

## 🎯 实验规则

| 约束 | 说明 |
|------|------|
| **零手写代码** | 所有代码必须由 Codex 写 — 包括应用逻辑、测试、CI、文档、内部工具、生产看板定义 |
| **真实产品** | 有内部日活用户和外部 alpha 测试者 |
| **团队规模** | 起初 3 名工程师，后来 7 名 |
| **周期** | 5 个月（2025年8月至2026年1月） |

## 📊 产出数据

| 指标 | 数据 |
|------|------|
| 代码量 | **~100 万行** |
| PR 数量 | **1,500+** |
| 人均日 PR | **3.5 个**（且随团队增长还在加速） |
| 效率提升 | 预估**比手写快 10 倍** |
| 单次 Agent 运行时长 | 最长 **6+ 小时**（人类睡觉时在跑） |

## 🧠 核心理念：人类转舵，Agent 执行

> **人类工程师的主要工作不再是写代码，而是设计环境、表达意图、构建反馈循环。**

早期进度比预期慢，**不是因为 Codex 能力不够，而是环境不够明确**。Agent 缺少做高层目标所需的工具、抽象和内部结构。

当任务失败时，修复方式几乎从来不是"再试一次"。人类工程师永远在问：**"缺少什么能力？怎么让它对 Agent 可读且可执行？"**

新的工程角色：
| 传统 | Agent-First |
|------|-----------|
| 写代码 | 设计让 Agent 能写出好代码的**环境** |
| Debug | 分析"Agent 缺什么能力"并补上 |
| Code Review | 把 review 标准编码成**自动 lint** |
| 文档 | 维护 Agent 可读的**知识库** |

## 📸 Codex 如何验证自己的工作

![Codex 用 Chrome DevTools 验证 UI](harness-codex-devtools.webp)

*Codex 通过 Chrome DevTools Protocol 直接驱动应用，截图、检查 DOM、复现 bug、验证修复。*

他们让应用**按 git worktree 独立启动**，每个 Codex 任务一个实例。Codex 可以：
- 启动应用
- 通过 CDP 截图、操作 DOM
- 复现 bug 并录制视频
- 实现修复后再录制一个视频
- 对比两个视频验证修复

## 🔭 给 Agent 完整的可观测性

![Codex 可观测性栈](harness-observability.svg)

*每个 worktree 有独立的可观测性栈（logs + metrics + traces），任务完成后自动销毁。*

Agent 可以用 **LogQL** 查日志，**PromQL** 查指标。这意味着 prompt 像这样变得可执行：
- "确保服务启动在 800ms 内完成"
- "这四条关键用户路径中，没有一个 span 超过 2 秒"

## 📄 AGENTS.md 的正确用法：地图而非百科全书

![Agent 知识的边界](harness-knowledge.webp)

*Agent 视角：只有仓库内可发现的版本化产物才存在。Slack、Google Docs、口头共识 = 对 Agent 不可见。*

他们试过巨大的 AGENTS.md，失败原因：

1. **上下文是稀缺资源** — 巨大的指令文件挤掉了任务、代码和相关文档的空间
2. **什么都"重要" = 什么都不重要** — Agent 最终只做局部模式匹配
3. **瞬间腐烂** — 人类不维护，Agent 分不清哪些还有效
4. **难以验证** — 单一文件无法做覆盖率、新鲜度、所有权检查

**正确做法**：AGENTS.md 只有 ~100 行，作为**目录**指向结构化知识库：

```
docs/
├── designs/          # 设计文档（带验证状态）
├── architecture/     # 架构地图（领域 + 包层级）
├── quality/          # 各领域质量评分
├── plans/
│   ├── active/       # 进行中的执行计划
│   ├── completed/    # 已完成计划
│   └── debt/         # 已知技术债
└── beliefs/          # Agent 操作的核心信念
```

**渐进式披露**：Agent 从小而稳定的入口开始，被教会"接下来去哪里找"。

他们还用**专门的 linter 和 CI 任务**验证知识库是否过时、交叉链接是否正确。还有一个**"文档园丁"Agent** 定期扫描过时文档并开修复 PR。

## 🏗️ 严格架构：Agent 的前提条件

![分层领域架构](harness-architecture.webp)

*每个业务领域分为固定层级，依赖方向严格验证。跨领域关注点通过 Providers 唯一接口进入。*

架构规则：
```
Types → Config → Repo → Service → Runtime → UI
```

跨领域关注点（auth、连接器、遥测、特性开关）通过唯一接口 **Providers** 进入。**其他一切依赖路径都被禁止，并通过自定义 linter 机械执行。**

> **这种架构通常在有上百个工程师时才会建。对 Agent 来说，它是早期前提条件 — 约束就是让 Agent 能保持速度而不架构腐烂的关键。**

自定义 linter 的错误消息里**嵌入了修复指令** — 让 Agent 读到报错就知道怎么改。在人类工作流中，这些规则可能显得吹毛求疵；**对 Agent 来说，它们是乘数**：编码一次，全局生效。

## 🤖 Agent 可以做的不只是写代码

Agent 生产的内容远不止应用代码：

| 产出 | 说明 |
|------|------|
| 📦 产品代码和测试 | 核心应用逻辑 |
| ⚙️ CI 配置和发布工具 | 持续集成/部署 |
| 🛠️ 内部开发者工具 | 开发效率工具 |
| 📝 文档和设计历史 | 包括版本化的设计决策 |
| 📊 评估框架 | 自动化评估 |
| 💬 Code Review 评论和回复 | Agent-to-Agent review |
| 📜 仓库管理脚本 | 自动化运维 |
| 📈 生产看板定义 | 监控面板 |

## 🔄 Agent 完整生命周期（端到端）

到最近，Codex 已经能**端到端驱动新功能**：

1. ✅ 验证代码库当前状态
2. 🐛 复现报告的 bug
3. 📹 录制 bug 视频
4. 🔧 实现修复
5. ✅ 用应用验证修复
6. 📹 录制修复后视频
7. 📝 开 PR
8. 💬 响应 Agent 和人类的 review 反馈
9. 🔄 检测并修复构建失败
10. ⚠️ 仅在需要判断时升级给人类
11. ✅ 合并变更

**单次 prompt → 完整的从 bug 到 fix 到 merge 的流程。**

> 注意：这种行为高度依赖于这个特定仓库的结构和工具，不能假设在没有类似投入的情况下能泛化 — 至少目前还不行。

## 🧹 "AI Slop" 垃圾回收

Agent 会复制仓库中已有的模式 — **包括不好的模式**。初期团队每周五花 20% 时间清理"AI 垃圾"，显然不可扩展。

解决方案：**Golden Principles + 自动垃圾回收**

- 将品味标准编码为 **Golden Principles**，存入仓库
- 后台 Codex 任务**定期扫描偏离**
- 自动开重构 PR（大部分 1 分钟内可 review，自动合并）
- **技术债像高利贷** — 持续小额偿还比攒着一次性清理好
- 人类品味**捕获一次，然后在每一行代码上持续执行**

具体规则示例：
1. 优先使用共享工具包而非手写 helper（集中管理不变量）
2. 不做"YOLO 式"数据探测 — 必须在边界验证或使用类型化 SDK

## 🔑 "无聊"技术的胜利

> **"无聊"的技术往往更适合 Agent — 可组合、API 稳定、训练集中大量存在。**

有时重新实现比依赖第三方好。例如，他们没有引入 `p-limit` 这样的通用包，而是让 Agent 自己实现了一个并发控制 helper：
- 与 OpenTelemetry instrumentation 紧密集成
- 100% 测试覆盖
- 行为完全符合运行时预期

> 把更多系统拉入 Agent 可检查、可验证、可修改的形式，不仅增加了 Codex 的杠杆，也帮助了其他 Agent（如 Aardvark）。

## 📐 合并哲学的转变

高吞吐量下，很多传统工程规范变得**适得其反**：

| 传统规范 | Agent-First 调整 |
|---------|-----------------|
| PR 必须人类 review | 几乎所有 review 推给 **Agent-to-Agent** |
| 严格的合并门禁 | **最小阻塞**，PR 短命 |
| 测试 flake 立即修复 | 用后续运行修复，不阻塞 |
| 等待 review 是常态 | **等待比纠错贵** |

> 在低吞吐量环境中这样做是不负责任的。但在这里，这往往是正确的权衡。

## 🤔 还不知道的事

- 完全 Agent 生成的系统在**年度尺度**上的架构一致性如何演进？
- 人类判断在哪里增加**最大杠杆**？如何编码使其**复利式增长**？
- 模型能力继续提升后，这个系统怎么变？

## 💡 核心启示总结

| 启示 | 解释 |
|------|------|
| **给地图不给手册** | AGENTS.md ~100 行目录，指向结构化 docs/ |
| **"无聊"技术更好** | 可组合、API 稳定、训练数据丰富 |
| **有时重写优于依赖** | Agent 重写的代码 100% 测试 + 完美集成 |
| **架构约束是前提** | 通常"百人团队"才需要的严格架构，对 Agent 是第一天就要建的 |
| **所有知识必须在仓库内** | Slack 讨论 = 对 Agent 不存在 |
| **错误消息里嵌修复指令** | 让 Agent 读到报错就知道怎么改 |
| **技术债像高利贷** | 持续偿还 > 攒着爆发 |
| **等待比纠错贵** | 高吞吐量下，最小阻塞合并门禁 |
| **给 Agent 可观测性** | LogQL、PromQL、截图、DOM — Agent 能自己调试 |
| **Agent Review Agent** | 人类从 review 撤退到更高层 |

## 🔗 资源

- **原文**: <https://openai.com/index/harness-engineering/>
- **Codex**: <https://openai.com/codex/>
- **执行计划指南**: <https://cookbook.openai.com/articles/codex_exec_plans>
- **Ralph Wiggum Loop**: <https://ghuntley.com/loop/>
- **Parse, Don't Validate**: <https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/>

---

*作者: 🦞 大龙虾*
*日期: 2026-03-01*
*标签: OpenAI / Codex / Agent-First / 零手写代码 / 百万行代码 / AGENTS.md / 工程实践 / 可观测性 / 架构*
